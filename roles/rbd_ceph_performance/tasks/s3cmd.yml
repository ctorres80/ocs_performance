---
- name: Select storage class
  shell: |
    export KUBECONFIG={{ kubeconfig }}
    oc get sc -o=custom-columns=NAME:.metadata.name,PROVISIONER:.provisioner | egrep "ocs-storagecluster-ceph-rgw|openshift-storage.noobaa.io" | awk  '{print $1}'
  register: ocs_storage_classes

- name: Available storage classess
  debug:
        msg:
          - "Select the storage class: "
          - "{{ ocs_storage_classes.stdout_lines }}"
- pause:
    prompt: |
          Select the storage class:
  register: storage_class

- pause:
    prompt: |
          How many fio pods ?
  register: fio_pods

- name: Create the fio+s3cmd statefulset fio-testing-performance accordingly
  shell: |
    export KUBECONFIG={{ kubeconfig }}
    oc create -f roles/rbd_ceph_performance/templates/fio-statefulset-s3cmd.yml
  ignore_errors: yes

- name: Scale fio for OCS to {{ fio_pods.user_input }} pods in namespace {{ name_space }}
  shell: |
    export KUBECONFIG={{ kubeconfig }}
    oc -n {{ name_space }} scale statefulset fio-testing-performance --replicas={{ fio_pods.user_input }}
  when: fio_pods.user_input != ''
  ignore_errors: yes

- name: Waiting for the availability of fio replicas={{ fio_pods.user_input }}
  shell: |
    export KUBECONFIG={{ kubeconfig }}
    oc -n {{ name_space }} get statefulsets fio-testing-performance -o yaml -o jsonpath='{.items[*]}{@.status.readyReplicas}{"\n"}'
  register: fio_pods_ready
  until: fio_pods_ready.stdout | int == fio_pods.user_input | int
  retries: 60
  delay: 10

- shell: |
    export KUBECONFIG={{ kubeconfig }}
    oc -n {{ name_space }} get pods -o wide
  register: fio_pods_print
  when: fio_pods.user_input != ''
  ignore_errors: yes

- name: fio pods available for OCS testing with storage class {{ storage_class.user_input }}
  debug:
    msg: "{{ fio_pods_print.stdout_lines }}"

- name: Let's create {{ fio_pods.user_input }} obcs with storageclass {{ storage_class.user_input }}
  shell: |
    sed -i '4d' roles/rbd_ceph_performance/templates/create_buckets.yml
    sed -i '$d' roles/rbd_ceph_performance/templates/create_buckets.yml
    sed -i '$d' roles/rbd_ceph_performance/templates/create_buckets.yml
    sed -i '/metadata:/a \ \ name: odf-obc-{{ item }}' roles/rbd_ceph_performance/templates/create_buckets.yml
    sed -i '/spec:/a \ \ storageClassName: {{ storage_class.user_input }}' roles/rbd_ceph_performance/templates/create_buckets.yml
    sed -i '/\ \ storageClassName:/a \ \ generateBucketName: odf-bucket-{{ item }}' roles/rbd_ceph_performance/templates/create_buckets.yml
    oc -n {{ name_space }} apply -f roles/rbd_ceph_performance/templates/create_buckets.yml
  args:
    warn: false
  with_sequence: start=0 end={{ fio_pods.user_input|int - 1 }}

- pause:
    prompt: |
          Valid I/O type for object injetion (Only one option is available):
          - write
          - randwrite
  register: io_type

- pause:
    prompt: |
          Valid I/O size in KB example:
          - 4, 8, 16, 32, 64, 128, 256, 1024, 2048, 4096 ?
  register: io_size

- pause:
    prompt: |
          Valid io_threads example:
          - 1, 2, 4, 8, 16, 32, 64, 128, 256, 512, 1024, 2048, 4096
  register: io_threads

- pause:
    prompt: |
          IO in GB total in GB (max 100):
  register: io_total

- pause:
    prompt: |
          IO rw_mix_read:
  register: rwmixread
  when: io_type.user_input == "readwrite" or io_type.user_input == "randrw"

- pause:
    prompt: |
          IO rwmixwrite:
  register: rwmixwrite
  when: io_type.user_input == "readwrite" or io_type.user_input == "randrw"


- name: Collect fio-testing-performance pod names
  shell: |
    export KUBECONFIG={{ kubeconfig }}
    oc get pods -n {{ name_space }} -l app=fio-testing-performance -o name -o=jsonpath='{range .items[*]}{.metadata.name}{"\n"}{end}'
  register: fio_ceph_tool_pods

- name: fio bench read, write, randwrite
  shell: |
    export KUBECONFIG={{ kubeconfig }}
    oc exec -n {{ name_space }} {{ item }} -it -- fio --randrepeat=1 --ioengine=libaio --direct=1 --gtod_reduce=1 --name=test --directory=/usr/share/ocs-pvc --bs={{ io_size.user_input }}K --iodepth={{ io_threads.user_input }} --size={{ io_total.user_input }}G --rw={{ io_type.user_input }} --nrfiles={{ io_total.user_input|int|round(0,'common') * 1048576 / io_size.user_input|int|round(0,'common') }} --refill_buffers=1
  loop: "{{ fio_ceph_tool_pods.stdout_lines }}"
  register: _create_instances
  async: 3600  # Maximum runtime in seconds. Adjust as needed.
  poll: 0  # Fire and continue (never poll)
  when: io_type.user_input == "read" or io_type.user_input == "write" or io_type.user_input == "randwrite" or io_type.user_input == "randread"

- name: fio --randrepeat=1 --ioengine=libaio --direct=1 --gtod_reduce=1 --name=test --directory=/usr/share/ocs-pvc --bs={{ io_size.user_input }}K --iodepth={{ io_threads.user_input }} --size={{ io_total.user_input }}G --rw={{ io_type.user_input }} --nrfiles={{ io_total.user_input|int|round(0,'common') * 1048576 / io_size.user_input|int|round(0,'common') }} --refill_buffers=1
  async_status:
    jid: "{{ item.ansible_job_id }}"
  register: _jobs
  until: _jobs.finished
  delay: 10  # Check every 10 seconds. Adjust as you like.
  retries: 360  # Retry up to 360 times. Adjust as needed.
  loop: "{{ _create_instances.results }}"
  when: io_type.user_input == "read" or io_type.user_input == "write" or io_type.user_input == "randwrite" or io_type.user_input == "randread"

- name: Print fio benchmarks
  debug:
    msg: "{{ item.stdout_lines }}"
  loop: "{{ _jobs.results }}"
  when: io_type.user_input == "read" or io_type.user_input == "write" or io_type.user_input == "randwrite" or io_type.user_input == "randread"

- name: s3cmd sync commands RGW
  shell: |
    if [ "{{ storage_class.user_input|string }}" = "ocs-storagecluster-ceph-rgw" ]; then
       endpoint_s3="rook-ceph-rgw-s3a"
    else
       endpoint_s3="s3"
    fi
    endpoint=$(oc get services $endpoint_s3 -n openshift-storage -o yaml -o jsonpath='{.spec.clusterIP}{"\n"}')
    for i in {0..{{ fio_pods.user_input|int - 1 }}}
        do
          access_key=$(oc get secrets odf-obc-$i -n {{ name_space }} -o jsonpath='{.data.AWS_ACCESS_KEY_ID}{"\n"}' | base64 -d)
          secret_key=$(oc get secrets odf-obc-$i -n {{ name_space }} -o jsonpath='{.data.AWS_SECRET_ACCESS_KEY}{"\n"}' | base64 -d)
          bucket=$(oc get configmap odf-obc-$i -n {{ name_space }} -o jsonpath='{.data.BUCKET_NAME}{"\n"}')
          echo "fio-testing-performance-$i -c fio-s3cmd -n {{ name_space }} -- s3cmd --host-bucket= --no-ssl --host=$endpoint --access_key=$access_key --secret_key=$secret_key sync /opt/data/ s3://$bucket"
    done
  register: s3_cmds
- name: Available storage classess
  debug:
    msg: "{{ s3_cmds.stdout_lines }}"
- name: s3cmd sync execute
  shell: |
    export KUBECONFIG={{ kubeconfig }}
    oc exec {{ item }}
  loop: "{{ s3_cmds.stdout_lines }}"
  register: _create_instances
  async: 3600  # Maximum runtime in seconds. Adjust as needed.
  poll: 0  # Fire and continue (never poll)

- name: Wait for s3cmd sync completed
  async_status:
    jid: "{{ item.ansible_job_id }}"
  register: _jobs
  until: _jobs.finished
  delay: 10  # Check every 5 seconds. Adjust as you like.
  retries: 360  # Retry up to 10 times. Adjust as needed.
  loop: "{{ _create_instances.results }}"

- name: Print s3cmd sync stats
  debug:
    msg: "{{ item.stdout_lines }}"
  loop: "{{ _jobs.results }}"

- name: I'm going to clean fio environment
  shell: |
    export KUBECONFIG={{ kubeconfig }}
    oc delete -f roles/rbd_ceph_performance/templates/fio-statefulset-s3cmd.yml
  ignore_errors: yes